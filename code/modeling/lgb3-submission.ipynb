{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bigger-joint",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neptune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "going-festival",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "outstanding-chile",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "european-standard",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"../../data/train.csv\"\n",
    "test_path = \"../../data/test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "celtic-persian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\n",
      "../../data/train.csv\n",
      "../../data/test.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"data\")\n",
    "print(train_path)\n",
    "print(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distributed-program",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "express-authorization",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "concerned-florence",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import precision_recall_curve, accuracy_score\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "agreed-speaking",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "answering-interaction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Oconnor, Frankie</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>209245</td>\n",
       "      <td>27.14</td>\n",
       "      <td>C12239</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Bryan, Drew</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27323</td>\n",
       "      <td>13.35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Owens, Kenneth</td>\n",
       "      <td>male</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>CA 457703</td>\n",
       "      <td>71.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Kramer, James</td>\n",
       "      <td>male</td>\n",
       "      <td>19.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A. 10866</td>\n",
       "      <td>13.04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Bond, Michael</td>\n",
       "      <td>male</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>427635</td>\n",
       "      <td>7.76</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass              Name   Sex    Age  SibSp  Parch  \\\n",
       "0            0         1       1  Oconnor, Frankie  male    NaN      2      0   \n",
       "1            1         0       3       Bryan, Drew  male    NaN      0      0   \n",
       "2            2         0       3    Owens, Kenneth  male   0.33      1      2   \n",
       "3            3         0       3     Kramer, James  male  19.00      0      0   \n",
       "4            4         1       3     Bond, Michael  male  25.00      0      0   \n",
       "\n",
       "      Ticket   Fare   Cabin Embarked  \n",
       "0     209245  27.14  C12239        S  \n",
       "1      27323  13.35     NaN        S  \n",
       "2  CA 457703  71.29     NaN        S  \n",
       "3   A. 10866  13.04     NaN        S  \n",
       "4     427635   7.76     NaN        S  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "floral-richmond",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    100000\n",
       "Survived       100000\n",
       "Pclass         100000\n",
       "Name           100000\n",
       "Sex            100000\n",
       "Age             96708\n",
       "SibSp          100000\n",
       "Parch          100000\n",
       "Ticket          95377\n",
       "Fare            99866\n",
       "Cabin           32134\n",
       "Embarked        99750\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "happy-infection",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "floppy-persian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100000</td>\n",
       "      <td>3</td>\n",
       "      <td>Holliday, Daniel</td>\n",
       "      <td>male</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24745</td>\n",
       "      <td>63.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100001</td>\n",
       "      <td>3</td>\n",
       "      <td>Nguyen, Lorraine</td>\n",
       "      <td>female</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13264</td>\n",
       "      <td>5.81</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100002</td>\n",
       "      <td>1</td>\n",
       "      <td>Harris, Heather</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25990</td>\n",
       "      <td>38.91</td>\n",
       "      <td>B15315</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100003</td>\n",
       "      <td>2</td>\n",
       "      <td>Larsen, Eric</td>\n",
       "      <td>male</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>314011</td>\n",
       "      <td>12.93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100004</td>\n",
       "      <td>1</td>\n",
       "      <td>Cleary, Sarah</td>\n",
       "      <td>female</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>26203</td>\n",
       "      <td>26.89</td>\n",
       "      <td>B22515</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass              Name     Sex   Age  SibSp  Parch  Ticket  \\\n",
       "0       100000       3  Holliday, Daniel    male  19.0      0      0   24745   \n",
       "1       100001       3  Nguyen, Lorraine  female  53.0      0      0   13264   \n",
       "2       100002       1   Harris, Heather  female  19.0      0      0   25990   \n",
       "3       100003       2      Larsen, Eric    male  25.0      0      0  314011   \n",
       "4       100004       1     Cleary, Sarah  female  17.0      0      2   26203   \n",
       "\n",
       "    Fare   Cabin Embarked  \n",
       "0  63.01     NaN        S  \n",
       "1   5.81     NaN        S  \n",
       "2  38.91  B15315        C  \n",
       "3  12.93     NaN        S  \n",
       "4  26.89  B22515        C  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "essential-maximum",
   "metadata": {},
   "source": [
    "# Feature Extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "tracked-greensboro",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southeast-richards",
   "metadata": {},
   "source": [
    "## Encoding Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "periodic-george",
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_encoder = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "intimate-crown",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sex_encoder.fit(list(df_train[\"Sex\"]) + list(df_test[\"Sex\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "accurate-helena",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"Sex_feature\"] = sex_encoder.transform(df_train[\"Sex\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "closed-collectible",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"Sex_feature\"] = sex_encoder.transform(df_test[\"Sex\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharp-classroom",
   "metadata": {},
   "source": [
    "## Encoding Embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "closing-camcorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "embarked_encoder = preprocessing.LabelEncoder()\n",
    "df_train[\"Embarked\"] = df_train[\"Embarked\"].fillna(\"UNK\")\n",
    "df_test[\"Embarked\"] = df_test[\"Embarked\"].fillna(\"UNK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "registered-linux",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embarked_encoder.fit(list(df_train[\"Embarked\"]) + list(df_test[\"Embarked\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "processed-denver",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"Embarked_feature\"] = embarked_encoder.transform(df_train[\"Embarked\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "stretch-notification",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"Embarked_feature\"] = embarked_encoder.transform(df_test[\"Embarked\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hindu-royalty",
   "metadata": {},
   "source": [
    "## Choice feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "electric-combine",
   "metadata": {},
   "outputs": [],
   "source": [
    "choice_feature = [\"Sex_feature\", \"Age\", \"Fare\", \"SibSp\", \"Pclass\", \"Embarked_feature\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "veterinary-third",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train[choice_feature]\n",
    "y = df_train[\"Survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "international-voluntary",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test[choice_feature]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "worse-roommate",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=3041975)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "foster-paint",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_train_data = lgb.Dataset(data=X_train, label=y_train, categorical_feature=[\"Sex_feature\", \"Embarked_feature\", \"Pclass\", \"SibSp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "christian-breeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_val_data = lgb.Dataset(data=X_val, label=y_val, reference=lgb_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "exterior-thermal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgbm_params = {\n",
    "#     'boosting': 'gbdt',          # dart (drop out trees) often performs better\n",
    "#     'application': 'binary',     # Binary classification\n",
    "#     'learning_rate': 0.02,       # Learning rate, controls size of a gradient descent step\n",
    "#     'min_data_in_leaf': 100,      # Data set is quite small so reduce this a bit\n",
    "#     'feature_fraction': 0.7,     # Proportion of features in each boost, controls overfitting\n",
    "#     'metric': 'auc',  # Area under ROC curve as the evaulation metric,\n",
    "#     'lambda_l1': 5e-05, \n",
    "#     'lambda_l2': 1.35e-08, \n",
    "#     'num_leaves': 216, \n",
    "#     'feature_fraction': 0.7458519562366559, \n",
    "#     'bagging_fraction': 0.7835116194444349, \n",
    "#     'bagging_freq': 2, \n",
    "#     'min_child_samples': 95\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "intensive-buddy",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_params = {\n",
    "    'boosting': 'gbdt',          # dart (drop out trees) often performs better\n",
    "    'application': 'binary',     # Binary classification\n",
    "    'learning_rate': 0.001,       # Learning rate, controls size of a gradient descent step\n",
    "    # 'feature_fraction': 0.7,     # Proportion of features in each boost, controls overfitting\n",
    "    'metric': 'auc',  # Area under ROC curve as the evaulation metric,\n",
    "    'lambda_l1': 5e-05, \n",
    "    'lambda_l2': 1.35e-08, \n",
    "    'num_leaves': 216, \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "concrete-consumption",
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment = neptune.create_experiment(name='LightGBM-training', params=lgbm_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conceptual-delaware",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "egyptian-trouble",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tt/miniconda3/envs/ml/lib/python3.8/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/home/tt/miniconda3/envs/ml/lib/python3.8/site-packages/lightgbm/basic.py:1554: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['Embarked_feature', 'Pclass', 'Sex_feature', 'SibSp']\n",
      "  warnings.warn('categorical_feature in Dataset is overridden.\\n'\n",
      "/home/tt/miniconda3/envs/ml/lib/python3.8/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/home/tt/miniconda3/envs/ml/lib/python3.8/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 38563, number of negative: 51437\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001718 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 430\n",
      "[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.428478 -> initscore=-0.288064\n",
      "[LightGBM] [Info] Start training from score -0.288064\n",
      "[200]\ttrain_data's auc: 0.847414\tval_data's auc: 0.835307\n",
      "[400]\ttrain_data's auc: 0.848688\tval_data's auc: 0.836097\n",
      "[600]\ttrain_data's auc: 0.84956\tval_data's auc: 0.836326\n",
      "[800]\ttrain_data's auc: 0.850331\tval_data's auc: 0.836395\n",
      "[1000]\ttrain_data's auc: 0.851131\tval_data's auc: 0.836581\n",
      "[1200]\ttrain_data's auc: 0.851922\tval_data's auc: 0.836724\n",
      "[1400]\ttrain_data's auc: 0.852587\tval_data's auc: 0.836764\n",
      "[1600]\ttrain_data's auc: 0.853282\tval_data's auc: 0.836817\n",
      "[1800]\ttrain_data's auc: 0.853921\tval_data's auc: 0.836984\n",
      "[2000]\ttrain_data's auc: 0.854584\tval_data's auc: 0.836876\n",
      "[2200]\ttrain_data's auc: 0.8552\tval_data's auc: 0.836877\n",
      "[2400]\ttrain_data's auc: 0.855957\tval_data's auc: 0.836791\n",
      "[2600]\ttrain_data's auc: 0.856704\tval_data's auc: 0.836708\n",
      "[2800]\ttrain_data's auc: 0.857476\tval_data's auc: 0.836698\n",
      "[3000]\ttrain_data's auc: 0.858251\tval_data's auc: 0.836674\n",
      "[3200]\ttrain_data's auc: 0.859028\tval_data's auc: 0.83666\n",
      "[3400]\ttrain_data's auc: 0.859777\tval_data's auc: 0.836531\n",
      "[3600]\ttrain_data's auc: 0.860561\tval_data's auc: 0.836475\n",
      "[3800]\ttrain_data's auc: 0.861376\tval_data's auc: 0.836411\n",
      "[4000]\ttrain_data's auc: 0.862131\tval_data's auc: 0.836291\n",
      "[4200]\ttrain_data's auc: 0.862881\tval_data's auc: 0.836194\n",
      "[4400]\ttrain_data's auc: 0.863702\tval_data's auc: 0.836122\n",
      "[4600]\ttrain_data's auc: 0.864514\tval_data's auc: 0.836013\n",
      "[4800]\ttrain_data's auc: 0.865317\tval_data's auc: 0.835899\n",
      "[5000]\ttrain_data's auc: 0.866139\tval_data's auc: 0.835822\n"
     ]
    }
   ],
   "source": [
    "num_boost_round = 5000\n",
    "# from neptunecontrib.monitoring.lightgbm import neptune_monitor\n",
    "model = lgb.train(lgbm_params, lgb_train_data, valid_sets = [lgb_train_data, lgb_val_data], valid_names=[\"train_data\", \"val_data\"], verbose_eval=200, num_boost_round=num_boost_round)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "photographic-beads",
   "metadata": {},
   "source": [
    "# Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "becoming-stake",
   "metadata": {},
   "outputs": [],
   "source": [
    "flag = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "informative-bryan",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"local\" in train_path:\n",
    "    flag = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "portable-provincial",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "orange-keyboard",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test, num_iteration=model.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "published-english",
   "metadata": {},
   "outputs": [],
   "source": [
    "if flag:\n",
    "    y_test = df_test[\"Survived\"]\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, y_pred)\n",
    "    df_curve = pd.DataFrame({\"precision\": precision, \"recall\": recall})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "moral-mandate",
   "metadata": {},
   "outputs": [],
   "source": [
    "if flag:\n",
    "    sns.lineplot(data=df_curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "employed-leadership",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds_meow = [i*0.01 for i in range(1,100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "featured-shell",
   "metadata": {},
   "outputs": [],
   "source": [
    "if flag: \n",
    "    acc_list = []\n",
    "    for threshold in thresholds_meow:\n",
    "        y_pred_one = [1 if y > threshold else 0 for y in y_pred]\n",
    "        accuracy = accuracy_score(y_test, y_pred_one)\n",
    "        acc_list.append(accuracy)\n",
    "    df_acc = pd.DataFrame({\"threshold\":thresholds_meow, \"accuracy\":acc_list})\n",
    "    ax = sns.lineplot(data=df_acc, x=\"threshold\", y=\"accuracy\")\n",
    "    ax.set_ylim(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "adult-oriental",
   "metadata": {},
   "outputs": [],
   "source": [
    "if flag:\n",
    "    max_acc = max(acc_list)\n",
    "    max_index = acc_list.index(max_acc)\n",
    "    best_threshold = thresholds_meow[max_index]\n",
    "    print(\"Best Acc \", max_acc)\n",
    "    print(\"Best threshold \", best_threshold)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equal-press",
   "metadata": {},
   "source": [
    "## Online submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "specified-acting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100002</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100004</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>199995</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>199996</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>199997</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>199998</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>199999</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId  Survived\n",
       "0           100000         0\n",
       "1           100001         0\n",
       "2           100002         1\n",
       "3           100003         0\n",
       "4           100004         1\n",
       "...            ...       ...\n",
       "99995       199995         1\n",
       "99996       199996         0\n",
       "99997       199997         0\n",
       "99998       199998         1\n",
       "99999       199999         1\n",
       "\n",
       "[100000 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not flag:\n",
    "    best_threshold = 0.5\n",
    "    y_pred_one = [1 if y > best_threshold else 0 for y in y_pred]\n",
    "    df_submission = pd.DataFrame({\"PassengerId\":df_test[\"PassengerId\"], \"Survived\": y_pred_one})\n",
    "    display(df_submission)\n",
    "    df_submission.to_csv(\"submission-lgb3_v2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "determined-acrylic",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "neptune": {
   "notebookId": "ca1789f9-9ff7-4ac5-a315-17a6906f852a",
   "projectVersion": 2
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
